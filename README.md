# American Sign Language to Text Converter  

This project is a Python-based application that converts American Sign Language (ASL) gestures into English text using computer vision and machine learning (Convolutional Neural Network). It leverages a camera to detect hand gestures, recognizes the patterns, and translates them into text.

---

## ‚ú® Benefits of the Program  
- **Accessibility**: Facilitates communication between people who use ASL and those who don‚Äôt understand it.  
- **Real-Time Conversion**: Provides instant translation of ASL to text, making it efficient for interactive use.  
- **Learning Aid**: Helps non-ASL users learn and practice sign language.  
- **Versatile**: Can be adapted for educational, professional, or casual environments.

---

## üõ†Ô∏è Tech Stack  
- **Programming Language**: Python  
- **Libraries**:  
  - [Mediapipe](https://google.github.io/mediapipe/)  
  - [CVZone](https://github.com/cvzone/cvzone)  
  - [TensorFlow](https://www.tensorflow.org/)
 
---

## üöÄ Getting Started  

### 1Ô∏è‚É£ Prerequisites  
Ensure you have Python installed (preferably version 3.7+).  

### 2Ô∏è‚É£ Clone the Repository  
```bash  
git clone https://github.com/yourgithubusername/asl-to-text-converter.git  
cd asl-to-text-converter
```

### 2Ô∏è‚É£ Clone the Repository

# Create the virtual environment  
python -m venv venv  

# Activate the virtual environment  
# Windows:  
venv\Scripts\activate  
# macOS/Linux:  
source venv/bin/activate  

### 4Ô∏è‚É£ Install Dependencies
```bash
pip install mediapipe cvzone tensorflow 
```

### 5Ô∏è‚É£ Run the Program
```bash
python main.py 
```

### üì∏ How It Works
The program uses your webcam to capture real-time hand gestures.
Mediapipe detects and tracks hand landmarks.
TensorFlow processes the gestures to classify them into English alphabets.
CVZone overlays the recognized text onto the video feed.
